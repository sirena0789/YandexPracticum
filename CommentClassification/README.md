## Описание проекта

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 
Необходимо обучить модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.

## Инструменты 

- pandas
- re
- sklearn.linear_model, LogisticRegression
- sklearn.ensemble, RandomForestClassifier
- sklearn.svm, LinearSVC
- sklearn.model_selection, train_test_split
- sklearn.model_selection, GridSearchCV
- sklearn.metrics, f1_score
- sklearn.pipeline, Pipeline
- sklearn.feature_extraction.text, TfidfVectorizer
- sklearn.preprocessing, StandardScaler
- nltk

## Итоги исследования

Задача проекта состояла в поиске "токсичных" комментариев из предлагаемого набора данных.  
В работе было проведено знакомство с данными, очистка текста от лишних символов, текст был привден к нижнему регистру.     
Далее была проведена лемматизация текста с использованием WordNetLemmatizer(), данные разделились на тестовую и обучающую выборки.
Затем были обучены три модели с подбором гиперпараметров с помощью GridSearchCV и Pipeline, который также проводит векторизацию кросс валидацию данных.  
По итогам обучения в лидеры вышли модели LogisticRegression с F1 0.765878 и LinearSVC с F1 0.758211.  
Отталкиваясь от запрашеваемой метрики тестированию подверглась модель LogisticRegression.  
Метрика качества F1 на тестировании прошла запрашеваемый порог.

##  Итоговая модель
- Модель: LogisticRegression;  
- Гиперпараметры: C = 4, penalty = l1, random_state=12, solver='liblinear', max_iter=200;     
- F1 на тестовой выборке: 0.774799;
- Время предсказания модели, сек: 2.03.

