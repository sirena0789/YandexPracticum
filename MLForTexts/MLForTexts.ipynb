{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7174ca6e",
   "metadata": {},
   "source": [
    "## Описание проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a97a97",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92381eb8",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59fc5e0",
   "metadata": {},
   "source": [
    "Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca0a0068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "368dd762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sirena0789/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sirena0789/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sirena0789/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/sirena0789/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sirena0789/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d84b78b",
   "metadata": {},
   "source": [
    "Загрузка файла с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44a45760",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/sirena0789/Downloads/toxic_comments.csv', index_col=0)\n",
    "corpus = data['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be85e5",
   "metadata": {},
   "source": [
    "Знакомство с одним из комментариев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dbdb1f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d9a1eb",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e9f6cf",
   "metadata": {},
   "source": [
    "Очистка текста от лишних символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "867aa711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    text = re.sub(r\"(?:\\n|\\r)\", \" \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z ]+\", \"\", text).strip()\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80f7b1e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus = corpus.apply(clear_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fd9b1f",
   "metadata": {},
   "source": [
    "Лемматизация текста"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b7f6f66",
   "metadata": {},
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "67bc3fba",
   "metadata": {},
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "corpus = corpus.apply(lambda sentence: \" \".join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(sentence)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c24f370",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "corpus = corpus.apply(lambda sentence: \" \".join([lemmatizer.lemmatize(w,\"n\") for w in nltk.word_tokenize(sentence)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd5e2deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         explanation why the edits made under my userna...\n",
       "1         daww he match this background colour im seemin...\n",
       "2         hey man im really not trying to edit war it ju...\n",
       "3         more i cant make any real suggestion on improv...\n",
       "4         you sir are my hero any chance you remember wh...\n",
       "                                ...                        \n",
       "159446    and for the second time of asking when your vi...\n",
       "159447    you should be ashamed of yourself that is a ho...\n",
       "159448    spitzer umm there no actual article for prosti...\n",
       "159449    and it look like it wa actually you who put on...\n",
       "159450    and i really dont think you understand i came ...\n",
       "Name: text, Length: 159292, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f82da6",
   "metadata": {},
   "source": [
    "Разделение выборок в соотношении 50/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e828b00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79646, 79646)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = data['toxic'].values\n",
    "features = corpus\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.5,\n",
    "                                                                            random_state=12, stratify=target)\n",
    "\n",
    "features_train.shape[0], features_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28589ebb",
   "metadata": {},
   "source": [
    "Загрузка стоп слов на английском языке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26962782",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94ac9cb",
   "metadata": {},
   "source": [
    "Векторизация текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cb435da",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "tf_idf_train = count_tf_idf.fit_transform(features_train) \n",
    "tf_idf_test = count_tf_idf.transform(features_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352bc2b7",
   "metadata": {},
   "source": [
    "**Вывод:**  \n",
    "Данные подготовлены к обучению моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db6244b",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8899ca53",
   "metadata": {},
   "source": [
    "Модель LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "453d46f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters: {'model__C': 4, 'model__penalty': 'l1'}\n",
      "Best score: 0.7658667158796392\n",
      "CPU times: user 3.55 s, sys: 1.26 s, total: 4.82 s\n",
      "Wall time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "pipe = Pipeline([('tfidf', TfidfVectorizer(stop_words=stopwords)),\n",
    "                 ('model',LogisticRegression(random_state = 12, solver='liblinear', max_iter=200))])\n",
    "\n",
    "param = [{'model__penalty' : ['l1', 'l2'], 'model__C': list(range(1,15,3))}]\n",
    "grid = GridSearchCV(pipe, param_grid=param, scoring='f1', cv=3, verbose=True, n_jobs=-1)\n",
    "model = grid.fit(features_train, target_train)\n",
    "best_model = model.best_estimator_\n",
    "print('Best parameters:', grid.best_params_)\n",
    "print('Best score:', grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b12c3f",
   "metadata": {},
   "source": [
    "Модель RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "665d76c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best parameters: {'model__max_depth': 15, 'model__max_features': 'sqrt', 'model__n_estimators': 50}\n",
      "Best score: 0.000740832224097631\n",
      "CPU times: user 5.26 s, sys: 2.57 s, total: 7.83 s\n",
      "Wall time: 53.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipe = Pipeline([('tfidf', TfidfVectorizer(stop_words=stopwords)),\n",
    "                 ('model',RandomForestClassifier(random_state = 12))])\n",
    "param = {'model__n_estimators': list(range(50,300,50)), 'model__max_depth':[5,15], 'model__max_features':['sqrt', 'log2']}\n",
    "grid = GridSearchCV(pipe, param_grid=param, scoring='f1', cv=3, verbose=True, n_jobs=-1)\n",
    "model = grid.fit(features_train, target_train)\n",
    "print('Best parameters:', grid.best_params_)\n",
    "print('Best score:', grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4fddd0",
   "metadata": {},
   "source": [
    "Модель LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "198e4fef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters: {'model__C': 1, 'model__penalty': 'l2'}\n",
      "Best score: 0.7585554063794299\n",
      "CPU times: user 3.32 s, sys: 1.2 s, total: 4.52 s\n",
      "Wall time: 17.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipe = Pipeline([('tfidf', TfidfVectorizer(stop_words=stopwords)),\n",
    "                 ('model', LinearSVC(random_state=12, max_iter=1000))])\n",
    "param = [{'model__penalty' : ['l1', 'l2'], 'model__C': list(range(1,15,3))}]\n",
    "grid = GridSearchCV(pipe, param_grid=param, scoring='f1', cv=3, verbose=True, n_jobs=-1)\n",
    "model = grid.fit(features_train, target_train)\n",
    "print('Best parameters:', grid.best_params_)\n",
    "print('Best score:', grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd00d040",
   "metadata": {},
   "source": [
    "Сведем результаты в таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bb952d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 на обучающей выборке</th>\n",
       "      <th>Время обучения на обучающей выборке, сек</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.765878</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.758211</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        F1 на обучающей выборке  \\\n",
       "LogisticRegression                     0.765878   \n",
       "RandomForestClassifier                 0.000000   \n",
       "LinearSVC                              0.758211   \n",
       "\n",
       "                        Время обучения на обучающей выборке, сек  \n",
       "LogisticRegression                                         154.0  \n",
       "RandomForestClassifier                                      52.8  \n",
       "LinearSVC                                                   17.9  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = ['LogisticRegression',\n",
    "         'RandomForestClassifier',\n",
    "         'LinearSVC']\n",
    "data = {'F1 на обучающей выборке':[0.765878, 0.0, 0.758211],\n",
    "        'Время обучения на обучающей выборке, сек':[154, 52.8, 17.9]}\n",
    "\n",
    "scores_data = pd.DataFrame(data=data, index=index)\n",
    "scores_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e43d37",
   "metadata": {},
   "source": [
    "**Вывод:**  \n",
    "Лучшей моделью на этапе обучения является:\n",
    "- Модель: LogisticRegression;  \n",
    "- Гиперпараметры: C = 4, penalty = l1, random_state=12, solver='liblinear', max_iter=200;     \n",
    "- F1 на обучающей выборке: 0.766028.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef22e080",
   "metadata": {},
   "source": [
    "## Тестирование лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cacf46c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.87 s, sys: 25.5 ms, total: 1.9 s\n",
      "Wall time: 1.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pred = best_model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a280475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7741628096923496"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(target_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd8aca1",
   "metadata": {},
   "source": [
    "##  Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c0adb9",
   "metadata": {},
   "source": [
    "    Задача проекта состояла в поиске \"токсичных\" комментариев из предлагаемого набора данных.  \n",
    "    В работе было проведено знакомство с данными, очистка текста от лишних символов, текст был привден к нижнему регистру.     \n",
    "    Далее была проведена лемматизация текста с использованием WordNetLemmatizer(), данные разделились на тестовую и обучающую выборки.\n",
    "    Затем были обучены три модели с подбором гиперпараметров с помощью GridSearchCV и Pipeline, который также проводит векторизацию кросс валидацию данных.  \n",
    "    По итогам обучения в лидеры вышли модели LogisticRegression с F1 0.765878 и LinearSVC с F1 0.758211.  \n",
    "    Отталкиваясь от запрашеваемой метрики тестированию подверглась модель LogisticRegression.  \n",
    "    Метрика качества F1 на тестировании прошла запрашеваемый порог."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05d5651",
   "metadata": {},
   "source": [
    " Итоговая модель:\n",
    "- Модель: LogisticRegression;  \n",
    "- Гиперпараметры: C = 4, penalty = l1, random_state=12, solver='liblinear', max_iter=200;     \n",
    "- F1 на тестовой выборке: 0.774799;\n",
    "- Время предсказания модели, сек: 2.03."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1486,
    "start_time": "2023-04-09T19:34:35.081Z"
   },
   {
    "duration": 2366,
    "start_time": "2023-04-09T19:34:36.569Z"
   },
   {
    "duration": 12,
    "start_time": "2023-04-09T19:34:38.937Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-09T19:34:38.950Z"
   },
   {
    "duration": 132,
    "start_time": "2023-04-09T19:34:38.956Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-09T19:34:39.090Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-09T19:34:39.092Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-09T19:34:39.093Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-09T19:34:39.094Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-09T19:34:39.096Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-09T19:34:39.097Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-09T19:34:39.098Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-09T19:34:39.099Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-09T19:34:39.100Z"
   },
   {
    "duration": 288,
    "start_time": "2023-04-09T19:36:47.280Z"
   },
   {
    "duration": 6,
    "start_time": "2023-04-09T19:37:12.246Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-09T19:37:22.118Z"
   },
   {
    "duration": 2391,
    "start_time": "2023-04-09T19:37:26.342Z"
   },
   {
    "duration": 11,
    "start_time": "2023-04-09T19:37:35.717Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-09T19:38:18.022Z"
   },
   {
    "duration": 132308,
    "start_time": "2023-04-09T19:38:26.313Z"
   },
   {
    "duration": 2525,
    "start_time": "2023-04-09T19:41:29.885Z"
   },
   {
    "duration": 79708,
    "start_time": "2023-04-09T19:41:41.558Z"
   },
   {
    "duration": 7,
    "start_time": "2023-04-09T19:43:30.760Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-09T19:43:59.191Z"
   },
   {
    "duration": 846,
    "start_time": "2023-04-09T19:43:59.198Z"
   },
   {
    "duration": 7,
    "start_time": "2023-04-09T19:44:00.046Z"
   },
   {
    "duration": 7,
    "start_time": "2023-04-09T19:44:00.055Z"
   },
   {
    "duration": 2685,
    "start_time": "2023-04-09T19:44:00.064Z"
   },
   {
    "duration": 8009,
    "start_time": "2023-04-09T19:44:02.751Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-09T19:44:10.762Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-09T19:44:15.813Z"
   },
   {
    "duration": 836,
    "start_time": "2023-04-09T19:44:15.819Z"
   },
   {
    "duration": 6,
    "start_time": "2023-04-09T19:44:16.656Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-09T19:44:16.664Z"
   },
   {
    "duration": 2758,
    "start_time": "2023-04-09T19:44:16.670Z"
   },
   {
    "duration": 79720,
    "start_time": "2023-04-09T19:44:19.429Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-09T19:45:39.151Z"
   },
   {
    "duration": 53,
    "start_time": "2023-04-09T19:45:39.158Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-09T19:45:39.212Z"
   },
   {
    "duration": 61,
    "start_time": "2023-04-09T19:45:39.217Z"
   },
   {
    "duration": 61,
    "start_time": "2023-04-09T19:45:39.280Z"
   },
   {
    "duration": 54,
    "start_time": "2023-04-09T19:45:39.343Z"
   },
   {
    "duration": 24,
    "start_time": "2023-04-09T19:45:39.399Z"
   },
   {
    "duration": 52,
    "start_time": "2023-04-09T19:45:39.425Z"
   },
   {
    "duration": 9,
    "start_time": "2023-04-09T19:45:39.479Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
